---\ndate_scraped: 2025-05-12\ntitle: Overview Of Prompting Strategies\n---\n\n# Overview of prompting strategies \n\nTo see an example of prompt design,\nrun the "Intro to Prompt Design" Jupyter notebook in one of the following\nenvironments:\n\n[Open\nin Colab](https://colab.research.google.com/github/GoogleCloudPlatform/generative-ai/blob/main/gemini/prompts/intro_prompt_design.ipynb)\n|\n[Open\nin Colab Enterprise](https://console.cloud.google.com/vertex-ai/colab/import/https%3A%2F%2Fraw.githubusercontent.com%2FGoogleCloudPlatform%2Fgenerative-ai%2Fmain%2Fgemini%2Fprompts%2Fintro_prompt_design.ipynb)\n|\n[Open\nin Vertex AI Workbench user-managed notebooks](https://console.cloud.google.com/vertex-ai/workbench/deploy-notebook?download_url=https%3A%2F%2Fraw.githubusercontent.com%2FGoogleCloudPlatform%2Fgenerative-ai%2Fmain%2Fgemini%2Fprompts%2Fintro_prompt_design.ipynb)\n|\n[View on GitHub](https://github.com/GoogleCloudPlatform/generative-ai/blob/main/gemini/prompts/intro_prompt_design.ipynb)\n\nWhile there\'s no right or wrong way to design a prompt, there are common strategies that\nyou can use to affect the model\'s responses. Rigorous testing and evaluation remain crucial for\noptimizing model performance.\n\nLarge language models (LLM) are trained on vast amounts of text data to learn the patterns and\nrelationships between units of language. When given some text (the prompt), language models can\npredict what is likely to come next, like a sophisticated autocompletion tool. Therefore, when\ndesigning prompts, consider the different factors that can influence what a model predicts comes\nnext.\n\n### Prompt engineering workflow\n\nPrompt engineering is a test-driven and iterative process that can enhance model performance.\nWhen creating prompts, it is important to clearly define the objectives and expected outcomes for\neach prompt and systematically test them to identify areas of improvement.\n\nThe following diagram shows the prompt engineering workflow:\n\n## How to create an effective prompt\n\nThere are two aspects of a prompt that ultimately affect its effectiveness:\n*content* and *structure*.\n\n- **Content:**\n\n In order to complete a task, the model needs all of the relevant information associated with\n the task. This information can include instructions, examples, contextual information, and so\n on. For details, see [Components of a prompt](#components-of-a-prompt).\n- **Structure:**\n\n Even when all the required information is provided in the prompt, giving the information\n structure helps the model parse the information. Things like the ordering, labeling, and the use\n of delimiters can all affect the quality of responses. For an example of prompt structure, see\n [Sample prompt template](#sample-prompt-template).\n\n## Components of a prompt\n\nThe following table shows the essential and optional components of a prompt:\n\n| Component | Description | Example |\n| --- | --- | --- |\n| Objective | What you want the model to achieve. Be specific and include any overarching objectives. Also called "mission" or "goal." | Your objective is to help students with math problems without directly giving them the answer. |\n| Instructions | Step-by-step instructions on how to perform the task at hand. Also called "task," "steps," or "directions." | 1. Understand what the problem is asking. 2. Understand where the student is stuck. 3. Give a hint for the next step of the problem. |\n| Optional components | | |\n| System instructions | Technical or environmental directives that may involve controlling or altering the model\'s behavior across a set of tasks. For many model APIs, system instructions are specified in a dedicated parameter. System instructions are available in Gemini\xa02.0\xa0Flash and later models. | You are a coding expert that specializes in rendering code for front-end interfaces. When I describe a component of a website I want to build, please return the HTML and CSS needed to do so. Do not give an explanation for this code. Also offer some UI design suggestions. |\n| Persona | Who or what the model is acting as. Also called "role" or "vision." | You are a math tutor here to help students with their math homework. |\n| Constraints | Restrictions on what the model must adhere to when generating a response, including what the model can and can\'t do. Also called "guardrails," "boundaries," or "controls." | Don\'t give the answer to the student directly. Instead, give hints at the next step towards solving the problem. If the student is completely lost, give them the detailed steps to solve the problem. |\n| Tone | The tone of the response. You can also influence the style and tone by specifying a persona. Also called "style," "voice," or "mood." | Respond in a casual and technical manner. |\n| Context | Any information that the model needs to refer to in order to perform the task at hand. Also called "background," "documents," or "input data." | A copy of the student\'s lesson plans for math. |\n| Few-shot examples | Examples of what the response should look like for a given prompt. Also called "exemplars" or "samples." | `input:` I\'m trying to calculate how many golf balls can fit into a box that has a one cubic meter volume. I\'ve converted one cubic meter into cubic centimeters and divided it by the volume of a golf ball in cubic centimeters, but the system says my answer is wrong. `output:` Golf balls are spheres and cannot be packed into a space with perfect efficiency. Your calculations take into account the maximum packing efficiency of spheres. |\n| Reasoning steps | Tell the model to explain its reasoning. This can sometimes improve the model\'s reasoning capability. Also called "thinking steps." | Explain your reasoning step-by-step. |\n| Response format | The format that you want the response to be in. For example, you can tell the model to output the response in JSON, table, Markdown, paragraph, bulleted list, keywords, elevator pitch, and so on. Also called "structure," "presentation," or "layout." | Format your response in Markdown. |\n| Recap | Concise repeat of the key points of the prompt, especially the constraints and response format, at the end of the prompt. | Don\'t give away the answer and provide hints instead. Always format your response in Markdown format. |\n| Safeguards | Grounds the questions to the mission of the bot. Also called "safety rules." | N/A |\n\nDepending on the specific tasks at hand, you might choose to include or exclude some of the\noptional components. You can also adjust the ordering of the components and check how that can\naffect the response.\n\n## Sample prompt template\n\nThe following prompt template shows you an example of what a well-structured prompt might look\nlike:\n\n|\n| |\n| **Sample prompt template:** ```python <OBJECTIVE_AND_PERSONA> You are a [insert a persona, such as a "math teacher" or "automotive expert"]. Your task is to... </OBJECTIVE_AND_PERSONA> <INSTRUCTIONS> To complete the task, you need to follow these steps: 1. 2. ... </INSTRUCTIONS> ------------- Optional Components ------------ <CONSTRAINTS> Dos and don\'ts for the following aspects 1. Dos 2. Don\'ts </CONSTRAINTS> <CONTEXT> The provided context </CONTEXT> <OUTPUT_FORMAT> The output format must be 1. 2. ... </OUTPUT_FORMAT> <FEW_SHOT_EXAMPLES> Here we provide some examples: 1. Example #1 Input: Thoughts: Output: ... </FEW_SHOT_EXAMPLES> <RECAP> Re-emphasize the key aspects of the prompt, especially the constraints, output format, etc. </RECAP> ``` |\n\n## Best practices\n\nPrompt design best practices include the following:\n\n- [Give clear and specific instructions](clear-instructions.md)\n- [Include few-shot examples](https://cloud.google.com/vertex-ai/generative-ai/docs/learn/prompts/few-shot-examples)\n- [Assign a role](https://cloud.google.com/vertex-ai/generative-ai/docs/learn/prompts/assign-role)\n- [Add contextual information](https://cloud.google.com/vertex-ai/generative-ai/docs/learn/prompts/contextual-information)\n- [Use system instructions](https://cloud.google.com/vertex-ai/generative-ai/docs/learn/prompts/system-instructions)\n- [Structure prompts](https://cloud.google.com/vertex-ai/generative-ai/docs/learn/prompts/structure-prompts)\n- [Instruct the model to explain its reasoning](https://cloud.google.com/vertex-ai/generative-ai/docs/learn/prompts/explain-reasoning)\n- [Break down complex tasks](https://cloud.google.com/vertex-ai/generative-ai/docs/learn/prompts/break-down-prompts)\n- [Experiment with parameter values](https://cloud.google.com/vertex-ai/generative-ai/docs/learn/prompts/adjust-parameter-values)\n- [Prompt iteration strategies](https://cloud.google.com/vertex-ai/generative-ai/docs/learn/prompts/prompt-iteration)\n\n## What\'s next\n\n- Explore examples of prompts in the\n [Prompt gallery](https://cloud.google.com/vertex-ai/generative-ai/docs/prompt-gallery).\n- Learn how to optimize prompts for use with\n [Google models](../models.md) by using the\n [Vertex AI prompt optimizer (Preview)](prompt-optimizer.md).\n- Learn about\n [responsible AI best practices and Vertex AI\'s safety filters](https://cloud.google.com/vertex-ai/generative-ai/docs/learn/responsible-ai).\n