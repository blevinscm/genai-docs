
<!doctype html>
<html lang="en" class="no-js">
  <head>
    
      <meta charset="utf-8">
      <meta name="viewport" content="width=device-width,initial-scale=1">
      
      
      
        <link rel="canonical" href="https://blevinscm.github.com/genai-docs/models/determine-eval/">
      
      
      
      
      <link rel="icon" href="../../assets/google-cloud-vertex-ai.png">
      <meta name="generator" content="mkdocs-1.6.1, mkdocs-material-9.6.14">
    
    
      
        <title>Define Your Evaluation Metricsbookmark_borderbookmarkstay Organized With Collectionssave And Categor - Vertex Generative AI</title>
      
    
    
      <link rel="stylesheet" href="../../assets/stylesheets/main.342714a4.min.css">
      
        
        <link rel="stylesheet" href="../../assets/stylesheets/palette.06af60db.min.css">
      
      


    
    
      
    
    
      
        
        
        <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
        <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Google+Sans:300,300i,400,400i,700,700i%7CRoboto+Mono:400,400i,700,700i&display=fallback">
        <style>:root{--md-text-font:"Google Sans";--md-code-font:"Roboto Mono"}</style>
      
    
    
      <link rel="stylesheet" href="../../stylesheets/extra.css">
    
      <link rel="stylesheet" href="../../js/chat-widget/chat-widget.css">
    
    <script>__md_scope=new URL("../..",location),__md_hash=e=>[...e].reduce(((e,_)=>(e<<5)-e+_.charCodeAt(0)),0),__md_get=(e,_=localStorage,t=__md_scope)=>JSON.parse(_.getItem(t.pathname+"."+e)),__md_set=(e,_,t=localStorage,a=__md_scope)=>{try{t.setItem(a.pathname+"."+e,JSON.stringify(_))}catch(e){}}</script>
    
      

    
    
    
  </head>
  
  
    
    
      
    
    
    
    
    <body dir="ltr" data-md-color-scheme="default" data-md-color-primary="black" data-md-color-accent="light-blue">
  
    
    <input class="md-toggle" data-md-toggle="drawer" type="checkbox" id="__drawer" autocomplete="off">
    <input class="md-toggle" data-md-toggle="search" type="checkbox" id="__search" autocomplete="off">
    <label class="md-overlay" for="__drawer"></label>
    <div data-md-component="skip">
      
        
        <a href="#define-your-evaluation-metrics-bookmark_borderbookmark" class="md-skip">
          Skip to content
        </a>
      
    </div>
    <div data-md-component="announce">
      
    </div>
    
    
      

<header class="md-header" data-md-component="header">
  <nav class="md-header__inner md-grid" aria-label="Header">
    <a href="../.." title="Vertex Generative AI" class="md-header__button md-logo" aria-label="Vertex Generative AI" data-md-component="logo">
      
  <img src="../../assets/google-cloud-vertex-ai.png" alt="logo">

    </a>
    <label class="md-header__button md-icon" for="__drawer">
      
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M3 6h18v2H3zm0 5h18v2H3zm0 5h18v2H3z"/></svg>
    </label>
    <div class="md-header__title" data-md-component="header-title">
      <div class="md-header__ellipsis">
        <div class="md-header__topic">
          <span class="md-ellipsis">
            Vertex Generative AI
          </span>
        </div>
        <div class="md-header__topic" data-md-component="header-topic">
          <span class="md-ellipsis">
            
              Define Your Evaluation Metricsbookmark_borderbookmarkstay Organized With Collectionssave And Categor
            
          </span>
        </div>
      </div>
    </div>
    
      
        <form class="md-header__option" data-md-component="palette">
  
    
    
    
    <input class="md-option" data-md-color-media="" data-md-color-scheme="default" data-md-color-primary="black" data-md-color-accent="light-blue"  aria-label="Switch to dark mode"  type="radio" name="__palette" id="__palette_0">
    
      <label class="md-header__button md-icon" title="Switch to dark mode" for="__palette_1" hidden>
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a4 4 0 0 0-4 4 4 4 0 0 0 4 4 4 4 0 0 0 4-4 4 4 0 0 0-4-4m0 10a6 6 0 0 1-6-6 6 6 0 0 1 6-6 6 6 0 0 1 6 6 6 6 0 0 1-6 6m8-9.31V4h-4.69L12 .69 8.69 4H4v4.69L.69 12 4 15.31V20h4.69L12 23.31 15.31 20H20v-4.69L23.31 12z"/></svg>
      </label>
    
  
    
    
    
    <input class="md-option" data-md-color-media="" data-md-color-scheme="slate" data-md-color-primary="black" data-md-color-accent="light-blue"  aria-label="Switch to light mode"  type="radio" name="__palette" id="__palette_1">
    
      <label class="md-header__button md-icon" title="Switch to light mode" for="__palette_0" hidden>
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 18c-.89 0-1.74-.2-2.5-.55C11.56 16.5 13 14.42 13 12s-1.44-4.5-3.5-5.45C10.26 6.2 11.11 6 12 6a6 6 0 0 1 6 6 6 6 0 0 1-6 6m8-9.31V4h-4.69L12 .69 8.69 4H4v4.69L.69 12 4 15.31V20h4.69L12 23.31 15.31 20H20v-4.69L23.31 12z"/></svg>
      </label>
    
  
</form>
      
    
    
      <script>var palette=__md_get("__palette");if(palette&&palette.color){if("(prefers-color-scheme)"===palette.color.media){var media=matchMedia("(prefers-color-scheme: light)"),input=document.querySelector(media.matches?"[data-md-color-media='(prefers-color-scheme: light)']":"[data-md-color-media='(prefers-color-scheme: dark)']");palette.color.media=input.getAttribute("data-md-color-media"),palette.color.scheme=input.getAttribute("data-md-color-scheme"),palette.color.primary=input.getAttribute("data-md-color-primary"),palette.color.accent=input.getAttribute("data-md-color-accent")}for(var[key,value]of Object.entries(palette.color))document.body.setAttribute("data-md-color-"+key,value)}</script>
    
    
    
      
      
        <label class="md-header__button md-icon" for="__search">
          
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"/></svg>
        </label>
        <div class="md-search" data-md-component="search" role="dialog">
  <label class="md-search__overlay" for="__search"></label>
  <div class="md-search__inner" role="search">
    <form class="md-search__form" name="search">
      <input type="text" class="md-search__input" name="query" aria-label="Search" placeholder="Search" autocapitalize="off" autocorrect="off" autocomplete="off" spellcheck="false" data-md-component="search-query" required>
      <label class="md-search__icon md-icon" for="__search">
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"/></svg>
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11z"/></svg>
      </label>
      <nav class="md-search__options" aria-label="Search">
        
        <button type="reset" class="md-search__icon md-icon" title="Clear" aria-label="Clear" tabindex="-1">
          
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M19 6.41 17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12z"/></svg>
        </button>
      </nav>
      
        <div class="md-search__suggest" data-md-component="search-suggest"></div>
      
    </form>
    <div class="md-search__output">
      <div class="md-search__scrollwrap" tabindex="0" data-md-scrollfix>
        <div class="md-search-result" data-md-component="search-result">
          <div class="md-search-result__meta">
            Initializing search
          </div>
          <ol class="md-search-result__list" role="presentation"></ol>
        </div>
      </div>
    </div>
  </div>
</div>
      
    
    
      <div class="md-header__source">
        <a href="https://github.com/blevinscm/genai-docs" title="Go to repository" class="md-source" data-md-component="source">
  <div class="md-source__icon md-icon">
    
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 496 512"><!--! Font Awesome Free 6.7.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M165.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6m-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3m44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9M244.8 8C106.1 8 0 113.3 0 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C428.2 457.8 496 362.9 496 252 496 113.3 383.5 8 244.8 8M97.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1m-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7m32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1m-11.4-14.7c-1.6 1-1.6 3.6 0 5.9s4.3 3.3 5.6 2.3c1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2"/></svg>
  </div>
  <div class="md-source__repository">
    GitHub
  </div>
</a>
      </div>
    
  </nav>
  
</header>
    
    <div class="md-container" data-md-component="container">
      
      
        
          
            
<nav class="md-tabs" aria-label="Tabs" data-md-component="tabs">
  <div class="md-grid">
    <ul class="md-tabs__list">
      
        
  
  
  
  
    <li class="md-tabs__item">
      <a href="../.." class="md-tabs__link">
        
  
  
    
  
  Home

      </a>
    </li>
  

      
        
  
  
  
  
    
    
      <li class="md-tabs__item">
        <a href="../../Generative-AI-on-Vertex-AI-Cookbook/" class="md-tabs__link">
          
  
  
    
  
  Learn

        </a>
      </li>
    
  

      
        
  
  
  
  
    
    
      <li class="md-tabs__item">
        <a href="../../agent-engine/Set-up-the-environment/" class="md-tabs__link">
          
  
  
    
  
  Build

        </a>
      </li>
    
  

      
        
  
  
  
  
    
    
      <li class="md-tabs__item">
        <a href="../Introduction-to-tuning/" class="md-tabs__link">
          
  
  
    
  
  Tune

        </a>
      </li>
    
  

      
        
  
  
  
  
    
    
      <li class="md-tabs__item">
        <a href="../../deploy/Deploy-generative-AI-models/" class="md-tabs__link">
          
  
  
    
  
  Deploy

        </a>
      </li>
    
  

      
        
  
  
  
  
    
    
      <li class="md-tabs__item">
        <a href="../../agent-engine/manage/Manage-deployed-agents/" class="md-tabs__link">
          
  
  
    
  
  Manage

        </a>
      </li>
    
  

      
        
  
  
  
  
    
    
      <li class="md-tabs__item">
        <a href="../evaluation-overview/" class="md-tabs__link">
          
  
  
    
  
  Optimize

        </a>
      </li>
    
  

      
    </ul>
  </div>
</nav>
          
        
      
      <main class="md-main" data-md-component="main">
        <div class="md-main__inner md-grid">
          
            
              
              <div class="md-sidebar md-sidebar--primary" data-md-component="sidebar" data-md-type="navigation" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    


  


<nav class="md-nav md-nav--primary md-nav--lifted" aria-label="Navigation" data-md-level="0">
  <label class="md-nav__title" for="__drawer">
    <a href="../.." title="Vertex Generative AI" class="md-nav__button md-logo" aria-label="Vertex Generative AI" data-md-component="logo">
      
  <img src="../../assets/google-cloud-vertex-ai.png" alt="logo">

    </a>
    Vertex Generative AI
  </label>
  
    <div class="md-nav__source">
      <a href="https://github.com/blevinscm/genai-docs" title="Go to repository" class="md-source" data-md-component="source">
  <div class="md-source__icon md-icon">
    
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 496 512"><!--! Font Awesome Free 6.7.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M165.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6m-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3m44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9M244.8 8C106.1 8 0 113.3 0 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C428.2 457.8 496 362.9 496 252 496 113.3 383.5 8 244.8 8M97.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1m-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7m32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1m-11.4-14.7c-1.6 1-1.6 3.6 0 5.9s4.3 3.3 5.6 2.3c1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2"/></svg>
  </div>
  <div class="md-source__repository">
    GitHub
  </div>
</a>
    </div>
  
  <ul class="md-nav__list" data-md-scrollfix>
    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../.." class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Home
    
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    
    
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
    
    
    
      
      
        
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_2" >
        
          
          <label class="md-nav__link" for="__nav_2" id="__nav_2_label" tabindex="0">
            
  
  
  <span class="md-ellipsis">
    Learn
    
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_2_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_2">
            <span class="md-nav__icon md-icon"></span>
            Learn
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../Generative-AI-on-Vertex-AI-Cookbook/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Vertex AI Generative AI Overview
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../Generative-AI-glossary/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Glossary
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../Generative-AI-on-Vertex-AI-release-notes/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Release Notes
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../supported-models_1/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Supported Models Overview
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../model-reference/gemini/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Gemini Models Overview
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../image/Imagen-on-Vertex-AI/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Imagen Models Overview
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../code/code-models-overview/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Code Models Overview
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../intelligent-code-commenter/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Intelligent Code Commenter
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../open-models/Use-Gemma-open-models/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Open Models (Gemma, Llama)
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../partner-models/use-partner-models/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Partner Models (Claude, AI21)
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../learn/prompts/Introduction-to-prompting/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Introduction to Prompting
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../learn/prompts/Overview-of-prompting-strategies/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Prompting Strategies
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../multimodal/Design-multimodal-prompts/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Multimodal Concepts
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../embeddings/Choose-an-embeddings-task-type/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Embeddings Overview
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../multimodal/Introduction-to-function-calling/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Function Calling Overview
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../grounding/Ground-responses-using-RAG/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Grounding Overview
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../agent-builder/Vertex-AI-Agent-Builder-overview/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Agent Builder Overview
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../agent-engine/Vertex-AI-Agent-Engine-overview/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Agent Engine Overview
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../rag-engine/Vertex-AI-RAG-Engine-overview/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    RAG Engine Overview
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../context-cache/Context-caching-overview/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Context Caching Overview
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../extensions/Extensions-overview/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Extensions Overview
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../example-store/Example-Store-overview/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Example Store Overview
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../Generative-AI-and-data-governance/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Data Governance
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../Security-controls-for-Generative-AI/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Security & Safety
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../deprecations/Model-versions-and-lifecycle/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Deprecations & Lifecycle
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../getting-help_1/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Getting Help
    
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
  
    
    
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
    
    
    
      
      
        
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_3" >
        
          
          <label class="md-nav__link" for="__nav_3" id="__nav_3_label" tabindex="0">
            
  
  
  <span class="md-ellipsis">
    Build
    
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_3_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_3">
            <span class="md-nav__icon md-icon"></span>
            Build
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../agent-engine/Set-up-the-environment/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Set up Environment (Agent Engine)
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../agent-engine/develop/Develop-a-LangChain-agent/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Develop LangChain Agent
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../agent-engine/develop/Develop-an-Agent-Development-Kit-agent/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Develop ADK Agent
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../agent-engine/use/Use-a-LangChain-agent/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Use LangChain Agent
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../agent-engine/use/Use-a-LangGraph-agent/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Use LangGraph Agent
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../chat/Design-chat-prompts/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Design Chat Prompts
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../multimodal/Text-generationbookmark_borderbookmark/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Generate Text with Gemini
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../image/Generate-images-using-text-prompts/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Generate Images with Imagen
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../Generate-images-with-Gemini/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Generate Images with Gemini
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../video/generate-videos/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Generate Video with Veo
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../embeddings/Get-batch-text-embeddings-predictions/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Get Text Embeddings
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../embeddings/Get-multimodal-embeddings/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Get Multimodal Embeddings
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../model-reference/Function-calling-reference/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Use Function Calling
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../grounding/Use-Google-Search-suggestions/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Use Grounding (Google Search)
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../grounding/Grounding-with-your-data/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Use Grounding (Your Data)
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../rag-engine/Use-data-ingestion-with-Vertex-AI-RAG-Engine/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Build with RAG Engine (Data Ingestion)
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../rag-engine/use-vertexai-vector-search/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Build with RAG Engine (Vector Search)
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../Use-a-Weaviate-database-with-Vertex-AI-RAG-Engine/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Build with RAG Engine (Weaviate)
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../context-cache/Create-a-context-cache/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Create Context Cache
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../extensions/Create-and-run-extensions/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Create Extensions
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../example-store/Retrieve-examples/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Use Example Store
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../multimodal/audio-understanding/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Multimodal Audio Understanding
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../multimodal/Document-understanding/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Multimodal Document Understanding
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../multimodal/Video-understanding/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Multimodal Video Understanding
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../prompt-gallery/samples/summarize_summarize_video/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Prompt Gallery Samples
    
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
  
    
    
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
    
    
    
      
      
        
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_4" >
        
          
          <label class="md-nav__link" for="__nav_4" id="__nav_4_label" tabindex="0">
            
  
  
  <span class="md-ellipsis">
    Tune
    
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_4_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_4">
            <span class="md-nav__icon md-icon"></span>
            Tune
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../Introduction-to-tuning/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Introduction to Model Tuning
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../About-supervised-fine-tuning-for-Gemini-models/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Tune Gemini Models (Supervised)
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../gemini-supervised-tuning-prepare/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Prepare Data for Gemini SFT
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../tune_gemini/text_tune/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Tune Gemini for Text
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../image/Style-customization/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Tune Imagen Models (Style/Subject)
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../Tune-function-calling/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Tune Function Calling
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../model-garden/LoRA-and-QLoRA-recommendations-for-LLMs/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    LoRA & QLoRA Recommendations
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../Fine-tune-RAG-transformations/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Fine-tune RAG Transformations
    
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
  
    
    
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
    
    
    
      
      
        
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_5" >
        
          
          <label class="md-nav__link" for="__nav_5" id="__nav_5_label" tabindex="0">
            
  
  
  <span class="md-ellipsis">
    Deploy
    
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_5_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_5">
            <span class="md-nav__icon md-icon"></span>
            Deploy
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../deploy/Deploy-generative-AI-models/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Deploy Generative AI Models
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../agent-engine/deploy/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Deploy Agent (Agent Engine)
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../Deployments-and-endpoints/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Deployments and Endpoints
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../model-garden/Use-models-in-Model-Garden/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Use Models from Model Garden
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../Purchase-Provisioned-Throughput/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Purchase Provisioned Throughput
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../Use-Provisioned-Throughput/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Use Provisioned Throughput
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../migrate/Migrate-to-the-Gemini-API-from-Azure-OpenAI/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Migrate from Azure OpenAI
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../migrate/openai/Using-OpenAI-libraries-with-Vertex-AI/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Use OpenAI Libraries with Vertex AI
    
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
  
    
    
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
    
    
    
      
      
        
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_6" >
        
          
          <label class="md-nav__link" for="__nav_6" id="__nav_6_label" tabindex="0">
            
  
  
  <span class="md-ellipsis">
    Manage
    
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_6_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_6">
            <span class="md-nav__icon md-icon"></span>
            Manage
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../agent-engine/manage/Manage-deployed-agents/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Manage Deployed Agents
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../agent-engine/manage/logging/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Agent Logging
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../agent-engine/manage/monitoring/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Agent Monitoring
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../agent-engine/sessions/Manage-sessions-using-direct-API-calls/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Manage Agent Sessions (API)
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../agent-engine/sessions/Manage-sessions-with-Agent-Development-Kit/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Manage Agent Sessions (ADK)
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../context-cache/Get-information-about-a-context-cache/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Manage Context Cache (Get/Delete)
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../Manage-your-RAG-knowledge-base-corpus/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Manage RAG Corpus
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../learn/Model-monitoring-metrics/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Model Monitoring Metrics
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../quotas/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Quotas & Limits
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../agent-engine/troubleshooting/Troubleshoot-deploying-an-agent/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Troubleshoot Agent Deployment
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../agent-engine/troubleshooting/Troubleshoot-developing-an-agent/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Troubleshoot Agent Development
    
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
  
    
    
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
    
    
    
      
      
        
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_7" >
        
          
          <label class="md-nav__link" for="__nav_7" id="__nav_7_label" tabindex="0">
            
  
  
  <span class="md-ellipsis">
    Optimize
    
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_7_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_7">
            <span class="md-nav__icon md-icon"></span>
            Optimize
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../evaluation-overview/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Model Evaluation Overview
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../Gen-AI-evaluation-service-overview/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Gen AI Evaluation Service
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../Run-AutoSxS-pipeline-to-perform-pairwise-model-based-evaluation/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Run AutoSxS (Pairwise Evaluation)
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../Evaluate-Gen-AI-agents/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Evaluate Agents
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../learn/prompts/Optimize-promptsbookmark_borderbookmark/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Optimize Prompts
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../Retrieval-and-ranking/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    RAG Retrieval and Ranking
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../model-reference/Vertex-AI-Model-Optimizer/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Vertex AI Model Optimizer
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../provisioned-throughput/Calculate-Provisioned-Throughput-requirements/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Calculate Provisioned Throughput
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../model-reference/count-tokens/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Count Tokens
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../context-cache/Context-caching-overview/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Context Caching Overview
    
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
  </ul>
</nav>
                  </div>
                </div>
              </div>
            
            
              
              <div class="md-sidebar md-sidebar--secondary" data-md-component="sidebar" data-md-type="toc" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    

<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
    
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#overview" class="md-nav__link">
    <span class="md-ellipsis">
      Overview
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#define-your-model-based-metrics" class="md-nav__link">
    <span class="md-ellipsis">
      Define your model-based metrics
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Define your model-based metrics">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#evaluate-translation-models" class="md-nav__link">
    <span class="md-ellipsis">
      Evaluate translation models
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#choose-between-pointwise-or-pairwise-evaluation" class="md-nav__link">
    <span class="md-ellipsis">
      Choose between pointwise or pairwise evaluation
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#computation-based-metrics" class="md-nav__link">
    <span class="md-ellipsis">
      Computation-based metrics
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Computation-based metrics">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#general-text-generation" class="md-nav__link">
    <span class="md-ellipsis">
      General text generation
    </span>
  </a>
  
    <nav class="md-nav" aria-label="General text generation">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#evaluation-criteria" class="md-nav__link">
    <span class="md-ellipsis">
      Evaluation criteria
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#metric-input-parameters" class="md-nav__link">
    <span class="md-ellipsis">
      Metric input parameters
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#output-scores" class="md-nav__link">
    <span class="md-ellipsis">
      Output scores
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#evaluation-criteria_1" class="md-nav__link">
    <span class="md-ellipsis">
      Evaluation criteria
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#metric-input-parameters_1" class="md-nav__link">
    <span class="md-ellipsis">
      Metric input parameters
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#output-scores_1" class="md-nav__link">
    <span class="md-ellipsis">
      Output scores
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#evaluation-criteria_2" class="md-nav__link">
    <span class="md-ellipsis">
      Evaluation criteria
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#metric-input-parameters_2" class="md-nav__link">
    <span class="md-ellipsis">
      Metric input parameters
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#output-scores_2" class="md-nav__link">
    <span class="md-ellipsis">
      Output scores
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#tool-use-and-function-calling" class="md-nav__link">
    <span class="md-ellipsis">
      Tool use and function calling
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Tool use and function calling">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#evaluation-criteria_3" class="md-nav__link">
    <span class="md-ellipsis">
      Evaluation criteria
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#metric-input-parameters_3" class="md-nav__link">
    <span class="md-ellipsis">
      Metric input parameters
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#output-scores_3" class="md-nav__link">
    <span class="md-ellipsis">
      Output scores
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#evaluation-criteria_4" class="md-nav__link">
    <span class="md-ellipsis">
      Evaluation criteria
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#metric-input-parameters_4" class="md-nav__link">
    <span class="md-ellipsis">
      Metric input parameters
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#output-scores_4" class="md-nav__link">
    <span class="md-ellipsis">
      Output scores
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#evaluation-criteria_5" class="md-nav__link">
    <span class="md-ellipsis">
      Evaluation criteria
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#metric-input-parameters_5" class="md-nav__link">
    <span class="md-ellipsis">
      Metric input parameters
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#output-scores_5" class="md-nav__link">
    <span class="md-ellipsis">
      Output scores
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#evaluation-criteria_6" class="md-nav__link">
    <span class="md-ellipsis">
      Evaluation criteria
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#metric-input-parameters_6" class="md-nav__link">
    <span class="md-ellipsis">
      Metric input parameters
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#output-scores_6" class="md-nav__link">
    <span class="md-ellipsis">
      Output scores
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#baseline-evaluation-quality-for-generative-tasks" class="md-nav__link">
    <span class="md-ellipsis">
      Baseline evaluation quality for generative tasks
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#whats-next" class="md-nav__link">
    <span class="md-ellipsis">
      What's next
    </span>
  </a>
  
</li>
      
    </ul>
  
</nav>
                  </div>
                </div>
              </div>
            
          
          
            <div class="md-content" data-md-component="content">
              <article class="md-content__inner md-typeset">
                
                  


  
    <a href="https://github.com/blevinscm/genai-docs/edit/main/docs/models/determine-eval.md" title="Edit this page" class="md-content__button md-icon">
      
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20.71 7.04c.39-.39.39-1.04 0-1.41l-2.34-2.34c-.37-.39-1.02-.39-1.41 0l-1.84 1.83 3.75 3.75M3 17.25V21h3.75L17.81 9.93l-3.75-3.75z"/></svg>
    </a>
  
  


<h1 id="define-your-evaluation-metrics-bookmark_borderbookmark">Define your evaluation metrics bookmark_borderbookmark<a class="headerlink" href="#define-your-evaluation-metrics-bookmark_borderbookmark" title="Permanent link">&para;</a></h1>
<p>The first step to evaluate your generative models or applications is to identify your evaluation goal and define your evaluation metrics. This page provides an overview of concepts related to defining evaluation metrics for your use case.</p>
<h2 id="overview">Overview<a class="headerlink" href="#overview" title="Permanent link">&para;</a></h2>
<p>Generative AI models can be used to create applications for a wide range of tasks, such as summarizing news articles, responding to customer inquiries, or assisting with code writing. The Gen AI evaluation service in Vertex AI lets you evaluate any model with explainable metrics.</p>
<p>For example, you might be developing an application to summarize articles. To evaluate your application's performance on that specific task, consider the criteria you would like to measure and the metrics that you would use to score them:</p>
<ul>
<li><strong>Criteria</strong>: Single or multiple dimensions you would like to evaluate upon, such as <code>conciseness</code>, <code>relevance</code>, <code>correctness</code>, or <code>appropriate choice of words</code>.</li>
<li><strong>Metrics</strong>: A single score that measures the model output against criteria.</li>
</ul>
<p>The Gen AI evaluation service provides two major types of metrics:</p>
<ul>
<li><a href="#model-based-metrics"><strong>Model-based metrics</strong></a>: Our model-based metrics assess your candidate model against a judge model. The judge model for most use cases is Gemini, but you can also use models such as <a href="https://github.com/google-research/metricx">MetricX</a> or <a href="https://huggingface.co/Unbabel/wmt22-comet-da">COMET</a> for translation use cases.</li>
</ul>
<p>You can measure model-based metrics <a href="#pointwise-pairwise">pairwise or pointwise</a>:</p>
<ul>
<li><strong>Pointwise metrics</strong>: Let the judge model assess the candidate model's output based on the evaluation criteria. For example, the score could be 0~5, where 0 means the response does not fit the criteria, while 5 means the response fits the criteria well.</li>
<li><strong>Pairwise metrics</strong>: Let the judge model compare the responses of two models and pick the better one. This is often used when comparing a candidate model with the baseline model. Pairwise metrics are only supported with Gemini as a judge model.</li>
<li><a href="#computation-based-metrics"><strong>Computation-based metrics</strong></a>: These metrics are computed using mathematical formulas to compare the model's output against a ground truth or reference. Commonly used computation-based metrics include ROUGE and BLEU.</li>
</ul>
<p>You can use computation-based metrics standalone, or together with model-based metrics. Use the following table to decide when to use model-based or computation-based metrics:</p>
<table>
<thead>
<tr>
<th></th>
<th>Evaluation approach</th>
<th>Data</th>
<th>Cost and speed</th>
</tr>
</thead>
<tbody>
<tr>
<td><a href="#model-based-metrics">Model-based metrics</a></td>
<td>Use a judge model to assess performance based on descriptive evaluation criteria</td>
<td>Ground truth is optional</td>
<td>Slightly more expensive and slower</td>
</tr>
<tr>
<td><a href="#computation-based-metrics">Computation-based metrics</a></td>
<td>Use mathematical formulas to assess performance</td>
<td>Ground truth is usually required</td>
<td>Low cost and fast</td>
</tr>
</tbody>
</table>
<p>To get started, see <a href="https://cloud.google.com/vertex-ai/generative-ai/docs/models/evaluation-dataset">Prepare your dataset</a> and <a href="https://cloud.google.com/vertex-ai/generative-ai/docs/models/run-evaluation">Run evaluation</a>.</p>
<h2 id="define-your-model-based-metrics">Define your model-based metrics<a class="headerlink" href="#define-your-model-based-metrics" title="Permanent link">&para;</a></h2>
<p>Model-based evaluation involves using a machine learning model as a judge model to evaluate the outputs of the candidate model.</p>
<p>Proprietary Google judge models, such as Gemini, are calibrated with human raters to ensure their quality. They are managed and available out of the box. The process of model-based evaluation varies based on the evaluation metrics you provide.</p>
<p>Model-based evaluation follows this process:</p>
<ol>
<li><strong>Data preparation</strong>: You provide evaluation data in the form of input prompts. The candidate models receive the prompts and generate corresponding responses.</li>
<li><strong>Evaluation</strong>: The evaluation metrics and generated responses are sent to the judge model. The judge model evaluates each response individually, providing a row-based assessment.</li>
<li><strong>Aggregation and explanation</strong>: Gen AI evaluation service aggregates these individual assessments into an overall score. The output also includes <a href="https://developers.google.com/machine-learning/glossary#chain-of-thought-prompting">chain-of-thought</a> explanations for each judgment, outlining the rationale behind the selection.</li>
</ol>
<p>Gen AI evaluation service offers the following options to set up your model-based metrics with the Vertex AI SDK:</p>
<table>
<thead>
<tr>
<th>Option</th>
<th>Description</th>
<th>Best for</th>
</tr>
</thead>
<tbody>
<tr>
<td>Use an existing example</td>
<td>Use a prebuilt metric prompt template to get started.</td>
<td>Common use cases, time-saving</td>
</tr>
<tr>
<td>Define metrics with our templated interface</td>
<td>Get guided assistance in defining your metrics. Our templated interface provides structure and suggestions.</td>
<td>Customization with support</td>
</tr>
<tr>
<td>Define metrics from scratch</td>
<td>Have complete control over your metric definitions.</td>
<td>Ideal for highly specific use cases. Requires more technical expertise and time investment.</td>
</tr>
</tbody>
</table>
<p>As an example, you might want to develop a generative AI application that returns fluent and entertaining responses. For this application, you can define two criteria for evaluation using the templated interface:</p>
<ul>
<li><strong>Fluency</strong>: Sentences flow smoothly, avoiding awkward phrasing or run-on sentences. Ideas and sentences connect logically, using transitions effectively where needed.</li>
<li><strong>Entertainment</strong>: Short, amusing text that incorporates emoji, exclamations, and questions to convey quick and spontaneous communication and diversion.</li>
</ul>
<p>To turn those two criteria into a metric, you want an overall score ranging from -1 ~ 1 called <code>custom_text_quality</code>. You can define a metric like this:</p>
<div class="language-python highlight"><pre><span></span><code><span id="__span-0-1"><a id="__codelineno-0-1" name="__codelineno-0-1" href="#__codelineno-0-1"></a><span class="c1"># Define a pointwise metric with two criteria: Fluency and Entertaining.</span>
</span><span id="__span-0-2"><a id="__codelineno-0-2" name="__codelineno-0-2" href="#__codelineno-0-2"></a><span class="n">custom_text_quality</span> <span class="o">=</span> <span class="n">PointwiseMetric</span><span class="p">(</span>
</span><span id="__span-0-3"><a id="__codelineno-0-3" name="__codelineno-0-3" href="#__codelineno-0-3"></a> <span class="n">metric</span><span class="o">=</span><span class="s2">&quot;custom_text_quality&quot;</span><span class="p">,</span>
</span><span id="__span-0-4"><a id="__codelineno-0-4" name="__codelineno-0-4" href="#__codelineno-0-4"></a> <span class="n">metric_prompt_template</span><span class="o">=</span><span class="n">PointwiseMetricPromptTemplate</span><span class="p">(</span>
</span><span id="__span-0-5"><a id="__codelineno-0-5" name="__codelineno-0-5" href="#__codelineno-0-5"></a> <span class="n">criteria</span><span class="o">=</span><span class="p">{</span>
</span><span id="__span-0-6"><a id="__codelineno-0-6" name="__codelineno-0-6" href="#__codelineno-0-6"></a> <span class="s2">&quot;fluency&quot;</span><span class="p">:</span> <span class="p">(</span>
</span><span id="__span-0-7"><a id="__codelineno-0-7" name="__codelineno-0-7" href="#__codelineno-0-7"></a> <span class="s2">&quot;Sentences flow smoothly and are easy to read, avoiding awkward&quot;</span>
</span><span id="__span-0-8"><a id="__codelineno-0-8" name="__codelineno-0-8" href="#__codelineno-0-8"></a> <span class="s2">&quot; phrasing or run-on sentences. Ideas and sentences connect&quot;</span>
</span><span id="__span-0-9"><a id="__codelineno-0-9" name="__codelineno-0-9" href="#__codelineno-0-9"></a> <span class="s2">&quot; logically, using transitions effectively where needed.&quot;</span>
</span><span id="__span-0-10"><a id="__codelineno-0-10" name="__codelineno-0-10" href="#__codelineno-0-10"></a> <span class="p">),</span>
</span><span id="__span-0-11"><a id="__codelineno-0-11" name="__codelineno-0-11" href="#__codelineno-0-11"></a> <span class="s2">&quot;entertaining&quot;</span><span class="p">:</span> <span class="p">(</span>
</span><span id="__span-0-12"><a id="__codelineno-0-12" name="__codelineno-0-12" href="#__codelineno-0-12"></a> <span class="s2">&quot;Short, amusing text that incorporates emojis, exclamations and&quot;</span>
</span><span id="__span-0-13"><a id="__codelineno-0-13" name="__codelineno-0-13" href="#__codelineno-0-13"></a> <span class="s2">&quot; questions to convey quick and spontaneous communication and&quot;</span>
</span><span id="__span-0-14"><a id="__codelineno-0-14" name="__codelineno-0-14" href="#__codelineno-0-14"></a> <span class="s2">&quot; diversion.&quot;</span>
</span><span id="__span-0-15"><a id="__codelineno-0-15" name="__codelineno-0-15" href="#__codelineno-0-15"></a> <span class="p">),</span>
</span><span id="__span-0-16"><a id="__codelineno-0-16" name="__codelineno-0-16" href="#__codelineno-0-16"></a> <span class="p">},</span>
</span><span id="__span-0-17"><a id="__codelineno-0-17" name="__codelineno-0-17" href="#__codelineno-0-17"></a> <span class="n">rating_rubric</span><span class="o">=</span><span class="p">{</span>
</span><span id="__span-0-18"><a id="__codelineno-0-18" name="__codelineno-0-18" href="#__codelineno-0-18"></a> <span class="s2">&quot;1&quot;</span><span class="p">:</span> <span class="s2">&quot;The response performs well on both criteria.&quot;</span><span class="p">,</span>
</span><span id="__span-0-19"><a id="__codelineno-0-19" name="__codelineno-0-19" href="#__codelineno-0-19"></a> <span class="s2">&quot;0&quot;</span><span class="p">:</span> <span class="s2">&quot;The response is somewhat aligned with both criteria&quot;</span><span class="p">,</span>
</span><span id="__span-0-20"><a id="__codelineno-0-20" name="__codelineno-0-20" href="#__codelineno-0-20"></a> <span class="s2">&quot;-1&quot;</span><span class="p">:</span> <span class="s2">&quot;The response falls short on both criteria&quot;</span><span class="p">,</span>
</span><span id="__span-0-21"><a id="__codelineno-0-21" name="__codelineno-0-21" href="#__codelineno-0-21"></a> <span class="p">},</span>
</span><span id="__span-0-22"><a id="__codelineno-0-22" name="__codelineno-0-22" href="#__codelineno-0-22"></a> <span class="p">),</span>
</span><span id="__span-0-23"><a id="__codelineno-0-23" name="__codelineno-0-23" href="#__codelineno-0-23"></a><span class="p">)</span>
</span></code></pre></div>
<p>For a complete list of metric prompt templates, see <a href="https://cloud.google.com/vertex-ai/generative-ai/docs/models/metrics-templates">Metric prompt templates for evaluation</a>.</p>
<h3 id="evaluate-translation-models">Evaluate translation models<a class="headerlink" href="#evaluate-translation-models" title="Permanent link">&para;</a></h3>
<p><strong>Preview</strong></p>
<p>This product or feature is subject to the "Pre-GA Offerings Terms" in the General Service Terms section
of the <a href="https://cloud.google.com/terms/service-terms#1">Service Specific Terms</a>.
Pre-GA products and features are available "as is" and might have limited support.
For more information, see the
<a href="https://cloud.google.com/products#product-launch-stages">launch stage descriptions</a>.</p>
<p>The <a href="../evaluation-overview/">Gen AI evaluation service</a> offers the following translation task evaluation metrics:</p>
<ul>
<li><a href="https://github.com/google-research/metricx">MetricX</a></li>
<li><a href="https://huggingface.co/Unbabel/wmt22-comet-da">COMET</a></li>
<li>BLEU</li>
</ul>
<p>MetricX and COMET are pointwise model-based metrics that have been trained for translation tasks. You can evaluate the quality and accuracy of translation model results for your content, whether they are outputs of NMT, TranslationLLM, or Gemini models.</p>
<p>You can also use Gemini as a judge model to evaluate your model for fluency, coherence, verbosity and text quality in combination with MetricX, COMET or BLEU.</p>
<ul>
<li>MetricX is an error-based metric developed by Google that predicts a floating point score between 0 and 25 representing the quality of a translation. MetricX is available both as a referenced-based and reference-free (QE) method. When you use this metric, a lower score is a better score, because it means there are fewer errors.</li>
<li>COMET employs a reference-based regression approach that provides scores ranging from 0 to 1, where 1 signifies a perfect translation.</li>
<li>BLEU (Bilingual Evaluation Understudy) is a <a href="./">computation-based metric</a>. The BLEU score indicates how similar the candidate text is to the reference text. A BLEU score value that is closer to one indicates that a translation is closer to the reference text.</li>
</ul>
<p>Note that BLEU scores are not recommended for comparing across different corpora and languages. For example, an English to German BLEU score of 50 is not comparable to a Japanese to English BLEU score of 50. Many translation experts have shifted to model-based metric approaches, which have higher correlation with human ratings and are more granular in identifying error scenarios.</p>
<p>To learn how to run evaluations for translation models, see <a href="https://cloud.google.com/vertex-ai/generative-ai/docs/models/run-evaluation#translation">Evaluate a translation model</a>.</p>
<h3 id="choose-between-pointwise-or-pairwise-evaluation">Choose between pointwise or pairwise evaluation<a class="headerlink" href="#choose-between-pointwise-or-pairwise-evaluation" title="Permanent link">&para;</a></h3>
<p>Use the following table to decide when you want to use pointwise or pairwise evaluation:</p>
<table>
<thead>
<tr>
<th></th>
<th>Definition</th>
<th>When to use</th>
<th>Example use cases</th>
</tr>
</thead>
<tbody>
<tr>
<td>Pointwise evaluation</td>
<td>Evaluate one model and generate scores based on the criteria</td>
<td>- When you need a score for each model being evaluated. - When it not difficult to define the rubric for each score.</td>
<td>- Understanding how your model behaves in production. - Explore strengths and weaknesses of a single model. - Identifying which behaviors to focus on when tuning. - Getting the baseline performance of a model.</td>
</tr>
<tr>
<td>Pairwise evaluation</td>
<td>Compare two models against each other, generating a preference based on the criteria</td>
<td>- When you want to compare two models and a score is not necessary. - When the score rubric for pointwise is difficult to define. For example, it may be difficult to define the rubric for 1~5 for pointwise text quality, but not as difficult to compare two models and output a preference directly.</td>
<td>- Determining which model to put into production. - Choose between model types. For example, Gemini-Pro versus Claude 3. - Choose between different prompts. - Determines if tuning made improvements to a baseline model.</td>
</tr>
</tbody>
</table>
<h2 id="computation-based-metrics">Computation-based metrics<a class="headerlink" href="#computation-based-metrics" title="Permanent link">&para;</a></h2>
<p>Computation-based metrics compare whether the LLM-generated results are
consistent with a ground-truth dataset of input and output pairs. The commonly
used metrics can be categorized into the following groups:</p>
<ul>
<li><strong>Lexicon-based metrics</strong>: Use math to calculate the string
 similarities between LLM-generated results and ground
 truth, such as <code>Exact Match</code> and <code>ROUGE</code>.</li>
<li><strong>Count-based metrics</strong>: Aggregate the number of rows that hit or miss certain
 ground-truth labels, such as <code>F1-score</code>, <code>Accuracy</code>, and <code>Tool Name Match</code>.</li>
<li><strong>Embedding-based metrics</strong>: Calculate the distance between the LLM-generated
 results and ground truth in the embedding space, reflecting their level of
 similarity.</li>
</ul>
<h3 id="general-text-generation">General text generation<a class="headerlink" href="#general-text-generation" title="Permanent link">&para;</a></h3>
<p>The following metrics help you to evaluate the model's ability to ensure the
responses are useful, safe, and effective for your users.</p>
<p><a href="#exact-match">Exact match</a> <a href="#bleu">BLEU</a> <a href="#rouge">ROUGE</a> 
More</p>
<p>The <code>exact_match</code> metric computes whether a model response
matches a reference exactly.</p>
<ul>
<li><strong>Token limit</strong>: None</li>
</ul>
<h4 id="evaluation-criteria">Evaluation criteria<a class="headerlink" href="#evaluation-criteria" title="Permanent link">&para;</a></h4>
<p>Not applicable.</p>
<h4 id="metric-input-parameters">Metric input parameters<a class="headerlink" href="#metric-input-parameters" title="Permanent link">&para;</a></h4>
<table>
<thead>
<tr>
<th>Input parameter</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>response</code></td>
<td>The LLM response.</td>
</tr>
<tr>
<td><code>reference</code></td>
<td>The golden LLM response for reference.</td>
</tr>
</tbody>
</table>
<h4 id="output-scores">Output scores<a class="headerlink" href="#output-scores" title="Permanent link">&para;</a></h4>
<table>
<thead>
<tr>
<th>Value</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td>0</td>
<td>Not matched</td>
</tr>
<tr>
<td>1</td>
<td>Matched</td>
</tr>
</tbody>
</table>
<p>The <code>bleu</code> (BiLingual Evaluation Understudy) metric holds the
result of an algorithm for evaluating the quality of the response, which has
been translated from one natural language to another natural language. The
quality of the response is considered to be the correspondence between a
<code>response</code> parameter and its <code>reference</code> parameter.</p>
<ul>
<li><strong>Token limit</strong>: None</li>
</ul>
<h4 id="evaluation-criteria_1">Evaluation criteria<a class="headerlink" href="#evaluation-criteria_1" title="Permanent link">&para;</a></h4>
<p>Not applicable.</p>
<h4 id="metric-input-parameters_1">Metric input parameters<a class="headerlink" href="#metric-input-parameters_1" title="Permanent link">&para;</a></h4>
<table>
<thead>
<tr>
<th>Input parameter</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>response</code></td>
<td>The LLM response.</td>
</tr>
<tr>
<td><code>reference</code></td>
<td>The golden LLM response for the reference.</td>
</tr>
</tbody>
</table>
<h4 id="output-scores_1">Output scores<a class="headerlink" href="#output-scores_1" title="Permanent link">&para;</a></h4>
<table>
<thead>
<tr>
<th>Value</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td>A float in the range of [0,1]</td>
<td>Higher scores indicate better translations. A score of <code>1</code> represents a perfect match to the <code>reference</code>.</td>
</tr>
</tbody>
</table>
<p>The <code>ROUGE</code> metric is used to compare the provided
<code>response</code> parameter against a <code>reference</code> parameter.
All <code>rouge</code> metrics return the F1 score. <code>rouge-l-sum</code> is calculated by default,
but you can <a href="https://cloud.google.com/vertex-ai/generative-ai/docs/model-reference/evaluation#rougeinput">specify the <code>rouge</code>
variant</a>
that you want to use.</p>
<ul>
<li><strong>Token limit</strong>: None</li>
</ul>
<h4 id="evaluation-criteria_2">Evaluation criteria<a class="headerlink" href="#evaluation-criteria_2" title="Permanent link">&para;</a></h4>
<p>Not applicable</p>
<h4 id="metric-input-parameters_2">Metric input parameters<a class="headerlink" href="#metric-input-parameters_2" title="Permanent link">&para;</a></h4>
<table>
<thead>
<tr>
<th>Input parameter</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>response</code></td>
<td>The LLM response.</td>
</tr>
<tr>
<td><code>reference</code></td>
<td>The golden LLM response for the reference.</td>
</tr>
</tbody>
</table>
<h4 id="output-scores_2">Output scores<a class="headerlink" href="#output-scores_2" title="Permanent link">&para;</a></h4>
<table>
<thead>
<tr>
<th>Value</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td>A float in the range of [0,1]</td>
<td>A score closer to <code>0</code> means poor similarity between <code>response</code> and <code>reference</code>. A score closer to <code>1</code> means strong similarity between <code>response</code> and <code>reference</code>.</td>
</tr>
</tbody>
</table>
<h3 id="tool-use-and-function-calling">Tool use and function calling<a class="headerlink" href="#tool-use-and-function-calling" title="Permanent link">&para;</a></h3>
<p>The following metrics help you to evaluate the model's ability to predict a
valid <a href="https://cloud.google.com/vertex-ai/generative-ai/docs/multimodal/function-calling">tool (function) call</a>.</p>
<p><a href="#call-valid">Call Validation</a> <a href="#name-match">Name Match</a> <a href="#parameter-key-match">Parameter Key Match</a> <a href="#parameter-kv-match">Parameter Key-Value Match</a> 
More</p>
<p>The <code>tool_call_valid</code> metric describes the model's ability to
predict a valid tool call. Only the first tool call is
inspected.</p>
<ul>
<li><strong>Token limit</strong>: None</li>
</ul>
<h4 id="evaluation-criteria_3">Evaluation criteria<a class="headerlink" href="#evaluation-criteria_3" title="Permanent link">&para;</a></h4>
<table>
<thead>
<tr>
<th>Evaluation criterion</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td>Validity</td>
<td>The model's output contains a valid tool call.</td>
</tr>
<tr>
<td>Formatting</td>
<td>A JSON dictionary contains the <code>name</code> and <code>arguments</code> fields.</td>
</tr>
</tbody>
</table>
<h4 id="metric-input-parameters_3">Metric input parameters<a class="headerlink" href="#metric-input-parameters_3" title="Permanent link">&para;</a></h4>
<table>
<thead>
<tr>
<th>Input parameter</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>prediction</code></td>
<td>The candidate model output, which is a JSON serialized string that contains <code>content</code> and <code>tool_calls</code> keys. The <code>content</code> value is the text output from the model. The <code>tool_calls</code> value is a JSON serialized string of a list of tool calls. Here is an example: <code>{"content": "", "tool_calls": [{"name": "book_tickets", "arguments": {"movie": "Mission Impossible Dead Reckoning Part 1", "theater":"Regal Edwards 14", "location": "Mountain View CA", "showtime": "7:30", "date": "2024-03-30","num_tix": "2"}}]}</code></td>
</tr>
<tr>
<td><code>reference</code></td>
<td>The ground-truth reference prediction, which follows the same format as <code>prediction</code>.</td>
</tr>
</tbody>
</table>
<h4 id="output-scores_3">Output scores<a class="headerlink" href="#output-scores_3" title="Permanent link">&para;</a></h4>
<table>
<thead>
<tr>
<th>Value</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td>0</td>
<td>Invalid tool call</td>
</tr>
<tr>
<td>1</td>
<td>Valid tool call</td>
</tr>
</tbody>
</table>
<p>The <code>tool_name_match</code> metric describes the model's ability to predict
a tool call with the correct tool name. Only the first tool call is inspected.</p>
<ul>
<li><strong>Token limit</strong>: None</li>
</ul>
<h4 id="evaluation-criteria_4">Evaluation criteria<a class="headerlink" href="#evaluation-criteria_4" title="Permanent link">&para;</a></h4>
<table>
<thead>
<tr>
<th>Evaluation criterion</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td>Name matching</td>
<td>The model-predicted tool call matches the reference tool call's name.</td>
</tr>
</tbody>
</table>
<h4 id="metric-input-parameters_4">Metric input parameters<a class="headerlink" href="#metric-input-parameters_4" title="Permanent link">&para;</a></h4>
<table>
<thead>
<tr>
<th>Input parameter</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>prediction</code></td>
<td>The candidate model output, which is a JSON serialized string that contains <code>content</code> and <code>tool_calls</code> keys. The <code>content</code> value is the text output from the model. The <code>tool_call</code> value is a JSON serialized string of a list of tool calls. Here is an example: <code>{"content": "","tool_calls": [{"name": "book_tickets", "arguments": {"movie": "Mission Impossible Dead Reckoning Part 1", "theater":"Regal Edwards 14", "location": "Mountain View CA", "showtime": "7:30", "date": "2024-03-30","num_tix": "2"}}]}</code></td>
</tr>
<tr>
<td><code>reference</code></td>
<td>The ground-truth reference prediction, which follows the same format as the <code>prediction</code>.</td>
</tr>
</tbody>
</table>
<h4 id="output-scores_4">Output scores<a class="headerlink" href="#output-scores_4" title="Permanent link">&para;</a></h4>
<table>
<thead>
<tr>
<th>Value</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td>0</td>
<td>Tool call name doesn't match the reference.</td>
</tr>
<tr>
<td>1</td>
<td>Tool call name matches the reference.</td>
</tr>
</tbody>
</table>
<p>The <code>tool_parameter_key_match</code> metric describes the model's ability to
predict a tool call with the correct parameter names.</p>
<ul>
<li><strong>Token limit</strong>: None</li>
</ul>
<h4 id="evaluation-criteria_5">Evaluation criteria<a class="headerlink" href="#evaluation-criteria_5" title="Permanent link">&para;</a></h4>
<table>
<thead>
<tr>
<th>Evaluation criterion</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td>Parameter matching ratio</td>
<td>The ratio between the number of predicted parameters that match the parameter names of the reference tool call and the total number of parameters.</td>
</tr>
</tbody>
</table>
<h4 id="metric-input-parameters_5">Metric input parameters<a class="headerlink" href="#metric-input-parameters_5" title="Permanent link">&para;</a></h4>
<table>
<thead>
<tr>
<th>Input parameter</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>prediction</code></td>
<td>The candidate model output, which is a JSON serialized string that contains the <code>content</code> and <code>tool_calls</code> keys. The <code>content</code> value is the text output from the model. The <code>tool_call</code> value is a JSON serialized string of a list of tool calls. Here is an example: <code>{"content": "", "tool_calls": [{"name": "book_tickets", "arguments": {"movie": "Mission Impossible Dead Reckoning Part 1", "theater":"Regal Edwards 14", "location": "Mountain View CA", "showtime": "7:30", "date": "2024-03-30","num_tix": "2"}}]}</code></td>
</tr>
<tr>
<td><code>reference</code></td>
<td>The ground-truth reference model prediction, which follows the same format as <code>prediction</code>.</td>
</tr>
</tbody>
</table>
<h4 id="output-scores_5">Output scores<a class="headerlink" href="#output-scores_5" title="Permanent link">&para;</a></h4>
<table>
<thead>
<tr>
<th>Value</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td>A float in the range of [0,1]</td>
<td>The higher score of <code>1</code> means more parameters match the <code>reference</code> parameters' names.</td>
</tr>
</tbody>
</table>
<p>The <code>tool_parameter_kv_match</code> metric describes the model's ability to
predict a tool call with the correct parameter names and key values.</p>
<ul>
<li><strong>Token limit</strong>: None</li>
</ul>
<h4 id="evaluation-criteria_6">Evaluation criteria<a class="headerlink" href="#evaluation-criteria_6" title="Permanent link">&para;</a></h4>
<table>
<thead>
<tr>
<th>Evaluation criterion</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td>Parameter matching ratio</td>
<td>The ratio between the number of the predicted parameters that match both the parameter names and values of the reference tool call and the total number of parameters.</td>
</tr>
</tbody>
</table>
<h4 id="metric-input-parameters_6">Metric input parameters<a class="headerlink" href="#metric-input-parameters_6" title="Permanent link">&para;</a></h4>
<table>
<thead>
<tr>
<th>Input parameter</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>prediction</code></td>
<td>The candidate model output, which is a JSON serialized string that contains <code>content</code> and <code>tool_calls</code> keys. The <code>content</code> value is the text output from the model. The <code>tool_call</code> value is a JSON serialized string of a list of tool calls. Here is an example: <code>{"content": "", "tool_calls": [{"name": "book_tickets", "arguments": {"movie": "Mission Impossible Dead Reckoning Part 1", "theater":"Regal Edwards 14", "location": "Mountain View CA", "showtime": "7:30", "date": "2024-03-30","num_tix": "2"}}]}</code></td>
</tr>
<tr>
<td><code>reference</code></td>
<td>The ground-truth reference prediction, which follows the same format as <code>prediction</code>.</td>
</tr>
</tbody>
</table>
<h4 id="output-scores_6">Output scores<a class="headerlink" href="#output-scores_6" title="Permanent link">&para;</a></h4>
<table>
<thead>
<tr>
<th>Value</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td>A float in the range of [0,1]</td>
<td>The higher score of <code>1</code> means more parameters match the <code>reference</code> parameters' names and values.</td>
</tr>
</tbody>
</table>
<p>In the generative AI evaluation service, you can <a href="https://cloud.google.com/vertex-ai/generative-ai/docs/models/run-evaluation">use computation-based metrics</a> through the Vertex AI SDK for Python.</p>
<h2 id="baseline-evaluation-quality-for-generative-tasks">Baseline evaluation quality for generative tasks<a class="headerlink" href="#baseline-evaluation-quality-for-generative-tasks" title="Permanent link">&para;</a></h2>
<p>When evaluating the output of generative AI models, note that the evaluation process is inherently subjective, and the quality of evaluation can vary depending on the specific task and evaluation criteria. This subjectivity also applies to human evaluators. For more information about the challenges of achieving consistent evaluation for generative AI models, see <a href="https://arxiv.org/pdf/2306.05685">Judging LLM-as-a-Judge
with MT-Bench and Chatbot Arena</a> and <a href="https://arxiv.org/pdf/2009.01325">Learning to summarize from human feedback</a>.</p>
<h2 id="whats-next">What's next<a class="headerlink" href="#whats-next" title="Permanent link">&para;</a></h2>
<ul>
<li>Find a <a href="https://cloud.google.com/vertex-ai/generative-ai/docs/models/metrics-templates">model-based metrics template</a>.</li>
<li><a href="https://cloud.google.com/vertex-ai/generative-ai/docs/models/evaluation-dataset">Prepare your evaluation dataset</a>.</li>
<li><a href="https://cloud.google.com/vertex-ai/generative-ai/docs/models/run-evaluation">Run an evaluation</a>.</li>
<li>Try an
 <a href="../evaluation-overview/">evaluation example notebook</a>.</li>
</ul>
<p>Was this helpful?</p>







  
  






                
              </article>
            </div>
          
          
  <script>var tabs=__md_get("__tabs");if(Array.isArray(tabs))e:for(var set of document.querySelectorAll(".tabbed-set")){var labels=set.querySelector(".tabbed-labels");for(var tab of tabs)for(var label of labels.getElementsByTagName("label"))if(label.innerText.trim()===tab){var input=document.getElementById(label.htmlFor);input.checked=!0;continue e}}</script>

<script>var target=document.getElementById(location.hash.slice(1));target&&target.name&&(target.checked=target.name.startsWith("__tabbed_"))</script>
        </div>
        
          <button type="button" class="md-top md-icon" data-md-component="top" hidden>
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M13 20h-2V8l-5.5 5.5-1.42-1.42L12 4.16l7.92 7.92-1.42 1.42L13 8z"/></svg>
  Back to top
</button>
        
      </main>
      
        <footer class="md-footer">
  
    
  
  <div class="md-footer-meta md-typeset">
    <div class="md-footer-meta__inner md-grid">
      <div class="md-copyright">
  
  
    Made with
    <a href="https://squidfunk.github.io/mkdocs-material/" target="_blank" rel="noopener">
      Material for MkDocs
    </a>
  
</div>
      
    </div>
  </div>
</footer>
      
    </div>
    <div class="md-dialog" data-md-component="dialog">
      <div class="md-dialog__inner md-typeset"></div>
    </div>
    
      <div class="md-progress" data-md-component="progress" role="progressbar"></div>
    
    
    
      
      <script id="__config" type="application/json">{"base": "../..", "features": ["content.code.annotate", "content.code.copy", "content.code.select", "content.tabs.link", "content.action.edit", "navigation.footer", "navigation.indexes", "navigation.instant", "navigation.instant.progress", "navigation.path", "navigation.top", "navigation.tracking", "toc.follow", "navigation.tabs", "navigation.sections", "navigation.tracking", "navigation.top", "search.suggest", "search.highlight"], "search": "../../assets/javascripts/workers/search.d50fe291.min.js", "tags": null, "translations": {"clipboard.copied": "Copied to clipboard", "clipboard.copy": "Copy to clipboard", "search.result.more.one": "1 more on this page", "search.result.more.other": "# more on this page", "search.result.none": "No matching documents", "search.result.one": "1 matching document", "search.result.other": "# matching documents", "search.result.placeholder": "Type to start searching", "search.result.term.missing": "Missing", "select.version": "Select version"}, "version": null}</script>
    
    
      <script src="../../assets/javascripts/bundle.13a4f30d.min.js"></script>
      
        <script src="../../js/chat-widget/gemini-client.js"></script>
      
        <script src="../../js/chat-widget/init.js"></script>
      
        <script src="../../js/chat-widget/setup-key.js"></script>
      
        <script src="../../js/chat-widget-helper.js"></script>
      
    
  </body>
</html>